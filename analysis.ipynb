{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install pandas\n",
    "! pip3 install geopandas\n",
    "! pip3 install levenshtein\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from Levenshtein import ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.2f\" % x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match rate\n",
    "\n",
    "# Load data into a DataFrame\n",
    "df = pd.read_csv(\"output/here-geocoding-result-scenario-1.csv\")\n",
    "\n",
    "# Add a new column to distinguish between matched and unmatched results\n",
    "df[\"is_geocoded\"] = df[\"longitude\"].apply(\n",
    "    lambda x: \"yes\" if not pd.isna(x) else \"no\")\n",
    "\n",
    "# Calculate Match Rate\n",
    "all_addresses_count = df.shape[0]\n",
    "matched_addresses_count = df[df[\"is_geocoded\"] == \"yes\"].shape[0]\n",
    "match_rate = matched_addresses_count * 100 / all_addresses_count\n",
    "print(f\"match rate: {match_rate}%\")\n",
    "\n",
    "# Convert geocoded addresses into a GeoDataFrame and set the coordinate reference system to EPSG:4326\n",
    "geocoded_addresses = df[df[\"is_geocoded\"] == \"yes\"]\n",
    "geocoded_addresses = gpd.GeoDataFrame(\n",
    "    geocoded_addresses,\n",
    "    geometry=gpd.points_from_xy(\n",
    "        geocoded_addresses[\"longitude\"], geocoded_addresses[\"latitude\"]\n",
    "    ),\n",
    ").set_crs(\"epsg:4326\")\n",
    "\n",
    "# Load the city boundary dataset into a GeoDataFrame and set the coordinate reference system to EPSG:4326\n",
    "city_boundary = gpd.read_file(\n",
    "    \"input/city-boundary.geojson\").set_crs(\"epsg:4326\")\n",
    "#  Create a single geometry representing the entire city boundary\n",
    "city_boundary = city_boundary[\"geometry\"].unary_union\n",
    "\n",
    "# Calculate the proportion of geocoded addresses that fall within the city boundaries\n",
    "geocoded_addresses_within_city = geocoded_addresses[\n",
    "    geocoded_addresses[\"geometry\"].within(city_boundary)\n",
    "]\n",
    "proportion = round(len(geocoded_addresses_within_city)\n",
    "                   * 100 / all_addresses_count, 1)\n",
    "print(\n",
    "    f\"proportion of geocoded results that fall within city boundaries: {proportion}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional accuracy\n",
    "\n",
    "# Load data into DataFrames\n",
    "baseline = pd.read_csv(\"input/input-addresses.csv\")\n",
    "geocoder = pd.read_csv(\"output/here-geocoding-result-scenario-1.csv\")\n",
    "\n",
    "# Convert DataFrames into GeoDataFrames with a local projection system (EPSG:3776 for Alberta) to calculate distances in meters\n",
    "baseline = (\n",
    "    gpd.GeoDataFrame(\n",
    "        baseline,\n",
    "        geometry=gpd.points_from_xy(\n",
    "            baseline[\"longitude\"], baseline[\"latitude\"]),\n",
    "    )\n",
    "    .set_crs(\"epsg:4326\")\n",
    "    .to_crs(\"epsg:3776\")\n",
    ")\n",
    "geocoder = (\n",
    "    gpd.GeoDataFrame(\n",
    "        geocoder,\n",
    "        geometry=gpd.points_from_xy(\n",
    "            geocoder[\"longitude\"], geocoder[\"latitude\"]),\n",
    "    )\n",
    "    .set_crs(\"epsg:4326\")\n",
    "    .to_crs(\"epsg:3776\")\n",
    ")\n",
    "\n",
    "# Calculate the distance between the geocoded points and the baseline\n",
    "baseline[\"distance\"] = baseline[\"geometry\"].distance(geocoder[\"geometry\"])\n",
    "\n",
    "# Calculate summary statistics\n",
    "summary_stats = baseline[\"distance\"].describe()\n",
    "print(summary_stats)\n",
    "\n",
    "\n",
    "# Classify distance values into 5 groups to better understand their distributions\n",
    "labels = [\"10m\", \"100m\", \"1km\", \"10km\", \"10km+\"]\n",
    "classes = [0, 10, 100, 1000, 10000, float(\"inf\")]\n",
    "\n",
    "baseline[\"distance_class\"] = pd.cut(\n",
    "    baseline[\"distance\"], bins=classes, labels=labels, include_lowest=True\n",
    ")\n",
    "\n",
    "# Calculate summary statistics\n",
    "counts = baseline[\"distance_class\"].value_counts(sort=False)\n",
    "print(counts)\n",
    "\n",
    "summary_stats = baseline[\"distance_class\"].describe()\n",
    "print(summary_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional similarity\n",
    "\n",
    "# Load data into DataFrames\n",
    "geocoder_1 = pd.read_csv(\"output/esri-geocoding-result-scenario-1.csv\")\n",
    "geocoder_2 = pd.read_csv(\"output/here-geocoding-result-scenario-1.csv\")\n",
    "\n",
    "# Conver DataFrames into GeoDataFrames with a local projection system (EPSG:3776 for Alberta) to calculate distances in meters\n",
    "geocoder_1 = (\n",
    "    gpd.GeoDataFrame(\n",
    "        geocoder_1,\n",
    "        geometry=gpd.points_from_xy(\n",
    "            geocoder_1[\"longitude\"], geocoder_1[\"latitude\"]),\n",
    "    )\n",
    "    .set_crs(\"epsg:4326\")\n",
    "    .to_crs(\"epsg:3776\")\n",
    ")\n",
    "geocoder_2 = (\n",
    "    gpd.GeoDataFrame(\n",
    "        geocoder_2,\n",
    "        geometry=gpd.points_from_xy(\n",
    "            geocoder_2[\"longitude\"], geocoder_2[\"latitude\"]),\n",
    "    )\n",
    "    .set_crs(\"epsg:4326\")\n",
    "    .to_crs(\"epsg:3776\")\n",
    ")\n",
    "\n",
    "# Calculate pairwise distance between the geocoded points\n",
    "df = pd.DataFrame()\n",
    "df[\"distance\"] = geocoder_1[\"geometry\"].distance(geocoder_2[\"geometry\"])\n",
    "\n",
    "# Calculate summary statistics\n",
    "summary_stats = df[\"distance\"].describe()\n",
    "print(summary_stats)\n",
    "\n",
    "# Classify distance values into 5 groups to better understand their distributions\n",
    "labels = [\"10m\", \"100m\", \"1km\", \"10km\", \"10km+\"]\n",
    "classes = [0, 10, 100, 1000, 10000, float(\"inf\")]\n",
    "\n",
    "df[\"distance_class\"] = pd.cut(\n",
    "    df[\"distance\"], bins=classes, labels=labels, include_lowest=True\n",
    ")\n",
    "\n",
    "# Calculate summary statistics\n",
    "counts = baseline[\"distance_class\"].value_counts(sort=False)\n",
    "print(counts)\n",
    "\n",
    "summary_stats = baseline[\"distance_class\"].describe()\n",
    "print(summary_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lexical accuracy with provided labels\n",
    "\n",
    "# Load data into DataFrames\n",
    "baseline = pd.read_csv(\"output/canada-post-geocoding-result-scenario-1.csv\")\n",
    "geocoder = pd.read_csv(\"output/esri-geocoding-result-scenario-1.csv\")\n",
    "\n",
    "# Rename the label column in all DataFrames and join them\n",
    "baseline = baseline[[\"id\", \"label\"]].rename(\n",
    "    columns={\"label\": \"label_baseline\"})\n",
    "geocoder = geocoder[[\"label\"]].rename(columns={\"label\": \"label_geocoder\"})\n",
    "df = pd.concat([baseline, geocoder], axis=1)\n",
    "\n",
    "# Calculate lexical accuracy\n",
    "df[\"lexical_accuracy\"] = df.apply(\n",
    "    lambda x: ratio(x[\"label_baseline\"], x[\"label_geocoder\"]), axis=1\n",
    ")\n",
    "\n",
    "# Calculate summary statistics\n",
    "summary_stats = df[\"lexical_accuracy\"].describe()\n",
    "print(summary_stats)\n",
    "\n",
    "# Classify distance values into 5 groups to better understand their distributions\n",
    "labels = [\"0.25\", \"0.5\", \"0.75\", \"1\"]\n",
    "classes = [0, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "df[\"lexical_accuracy_class\"] = pd.cut(\n",
    "    df[\"lexical_accuracy\"], bins=classes, labels=labels, include_lowest=True\n",
    ")\n",
    "\n",
    "# Calculate summary statistics\n",
    "counts = df[\"lexical_accuracy_class\"].value_counts(sort=False)\n",
    "print(counts)\n",
    "\n",
    "summary_stats = df[\"lexical_accuracy_class\"].describe()\n",
    "print(summary_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lexical accuracy with constructed labels\n",
    "\n",
    "# Load data into DataFrames\n",
    "baseline = pd.read_csv(\"output/canada-post-geocoding-result-scenario-1.csv\")\n",
    "geocoder = pd.read_csv(\"output/esri-geocoding-result-scenario-1.csv\")\n",
    "\n",
    "# Construct labels and join DataFrames\n",
    "baseline[\"label_baseline\"] = baseline.apply(\n",
    "    lambda x: f\"{x['street_name']} {x['city']}, {x['province']}, {x['postal_code']}, {x['country']}\",\n",
    "    axis=1,\n",
    ")\n",
    "geocoder[\"label_geocoder\"] = geocoder.apply(\n",
    "    lambda x: f\"{x['street_number']} {x['street_name']}, {x['city']}, {x['province']}, {x['postal_code']}, {x['country']}\",\n",
    "    axis=1,\n",
    ")\n",
    "df = pd.concat([baseline, geocoder], axis=1)\n",
    "\n",
    "\n",
    "# Calculate lexical accuracy\n",
    "df[\"lexical_accuracy\"] = df.apply(\n",
    "    lambda x: ratio(x[\"label_baseline\"], x[\"label_geocoder\"]), axis=1\n",
    ")\n",
    "\n",
    "# Calculate summary statistics\n",
    "summary_stats = df[\"lexical_accuracy\"].describe()\n",
    "print(summary_stats)\n",
    "\n",
    "# Classify distance values into 5 groups to better understand their distributions\n",
    "labels = [\"0.25\", \"0.5\", \"0.75\", \"1\"]\n",
    "classes = [0, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "df[\"lexical_accuracy_class\"] = pd.cut(\n",
    "    df[\"lexical_accuracy\"], bins=classes, labels=labels, include_lowest=True\n",
    ")\n",
    "\n",
    "# Calculate summary statistics\n",
    "counts = df[\"lexical_accuracy_class\"].value_counts(sort=False)\n",
    "print(counts)\n",
    "\n",
    "summary_stats = df[\"lexical_accuracy_class\"].describe()\n",
    "print(summary_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lexical similarity with provided labels\n",
    "\n",
    "# Load data into DataFrames\n",
    "geocoder_1 = pd.read_csv(\"output/esri-geocoding-result-scenario-1.csv\")\n",
    "geocoder_2 = pd.read_csv(\"output/here-geocoding-result-scenario-1.csv\")\n",
    "\n",
    "# Rename the label column in all DataFrames and join them\n",
    "geocoder_1 = geocoder_1[[\"id\", \"label\"]].rename(\n",
    "    columns={\"label\": \"label_geocoder_1\"})\n",
    "geocoder_2 = geocoder_2[[\"label\"]].rename(\n",
    "    columns={\"label\": \"label_geocoder_2\"})\n",
    "df = pd.concat([geocoder_1, geocoder_2], axis=1)\n",
    "\n",
    "# Calculate lexical similarity\n",
    "df[\"lexical_similarity\"] = df.apply(\n",
    "    lambda x: ratio(x[\"label_geocoder_1\"], x[\"label_geocoder_2\"]), axis=1\n",
    ")\n",
    "\n",
    "# Calculate summary statistics\n",
    "summary_stats = df[\"lexical_similarity\"].describe()\n",
    "print(summary_stats)\n",
    "\n",
    "# Classify distance values into 5 groups to better understand their distributions\n",
    "labels = [\"0.25\", \"0.5\", \"0.75\", \"1\"]\n",
    "classes = [0, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "df[\"lexical_similarity_class\"] = pd.cut(\n",
    "    df[\"lexical_similarity\"], bins=classes, labels=labels, include_lowest=True\n",
    ")\n",
    "\n",
    "# Calculate summary statistics\n",
    "counts = df[\"lexical_similarity_class\"].value_counts(sort=False)\n",
    "print(counts)\n",
    "\n",
    "summary_stats = df[\"lexical_similarity_class\"].describe()\n",
    "print(summary_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lexical similarity with constructed labels\n",
    "\n",
    "# Load data into DataFrames\n",
    "geocoder_1 = pd.read_csv(\"output/esri-geocoding-result-scenario-1.csv\")\n",
    "geocoder_2 = pd.read_csv(\"output/here-geocoding-result-scenario-1.csv\")\n",
    "\n",
    "# Rename the label column in all DataFrames and join them\n",
    "# Construct labels and join DataFrames\n",
    "geocoder_1[\"label_geocoder_1\"] = geocoder_1.apply(\n",
    "    lambda x: f\"{x['street_name']} {x['city']}, {x['province']}, {x['postal_code']}, {x['country']}\",\n",
    "    axis=1,\n",
    ")\n",
    "geocoder_2[\"label_geocoder_2\"] = geocoder_2.apply(\n",
    "    lambda x: f\"{x['street_number']} {x['street_name']}, {x['city']}, {x['province']}, {x['postal_code']}, {x['country']}\",\n",
    "    axis=1,\n",
    ")\n",
    "df = pd.concat([geocoder_1, geocoder_2], axis=1)\n",
    "\n",
    "# Calculate lexical similarity\n",
    "df[\"lexical_similarity\"] = df.apply(\n",
    "    lambda x: ratio(x[\"label_geocoder_1\"], x[\"label_geocoder_2\"]), axis=1\n",
    ")\n",
    "\n",
    "# Calculate summary statistics\n",
    "summary_stats = df[\"lexical_similarity\"].describe()\n",
    "print(summary_stats)\n",
    "\n",
    "# Classify distance values into 5 groups to better understand their distributions\n",
    "labels = [\"0.25\", \"0.5\", \"0.75\", \"1\"]\n",
    "classes = [0, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "df[\"lexical_similarity_class\"] = pd.cut(\n",
    "    df[\"lexical_similarity\"], bins=classes, labels=labels, include_lowest=True\n",
    ")\n",
    "\n",
    "# Calculate summary statistics\n",
    "counts = df[\"lexical_similarity_class\"].value_counts(sort=False)\n",
    "print(counts)\n",
    "\n",
    "summary_stats = df[\"lexical_similarity_class\"].describe()\n",
    "print(summary_stats)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
